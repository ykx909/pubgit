{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Awork\\Anaconda3\\envs\\pytorch113\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of the model checkpoint at C:\\Users\\cccql\\.cache\\huggingface\\hub\\models--bert-base-chinese\\snapshots\\38fda776740d17609554e879e3ac7b9837bdb5ee were not used when initializing BertModel: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (1): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (2): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (3): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (4): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (5): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (6): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (7): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (8): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (9): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (10): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (11): BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 提前导包\n",
    "import numpy as np\n",
    "import torch\n",
    "from transformers import BertConfig,BertModel,BertTokenizer\n",
    "from transformers import BertForMaskedLM,BertForNextSentencePrediction\n",
    "from transformers import BertModel\n",
    "\n",
    "model_name = 'bert-base-chinese'\n",
    "MODEL_PATH = r'C:\\Users\\cccql\\.cache\\huggingface\\hub\\models--bert-base-chinese\\snapshots\\38fda776740d17609554e879e3ac7b9837bdb5ee'\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_PATH)\n",
    "config = BertConfig.from_pretrained(MODEL_PATH)\n",
    "config.output_hidden_states = True\n",
    "config.output_attentions = True\n",
    "model = BertModel.from_pretrained(MODEL_PATH,config=config)\n",
    "\n",
    "model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'input_ids': [[101, 2769, 679, 1599, 3614, 6821, 702, 686, 4518, 511, 102, 2769, 738, 3221, 8013, 102], [101, 8975, 9879, 102, 166, 8177, 8225, 8253, 102]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1], [0, 0, 0, 0, 1, 1, 1, 1, 1]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 1, 1]]}\n",
      "[101, 2769, 679, 1599, 3614, 6821, 702, 686, 4518, 511, 102]\n",
      "{'input_ids': [101, 2769, 679, 1599, 3614, 6821, 702, 686, 4518, 511, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[101, 2769, 679, 1599, 3614, 6821, 702, 686, 4518, 511, 102]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "- encode仅返回input_ids\n",
    "- encode_plus返回所有编码信息\n",
    "    - ‘input_ids’：是单词在词典中的编码\n",
    "    - ‘token_type_ids’：区分两个句子的编码（上句全为0，下句全为1）\n",
    "    - ‘attention_mask’：指定对哪些词进行self-Attention操作\n",
    "'''\n",
    "print(tokenizer([['我不喜欢这个世界。','我也是！'],['asdd','xcvz    ']]))\n",
    "print(tokenizer.encode('我不喜欢这个世界。'))\n",
    "print(tokenizer.encode_plus('我不喜欢这个世界。'))\n",
    "a = tokenizer.encode_plus('我不喜欢这个世界。')\n",
    "a.input_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '我', '不', '喜', '欢', '这', '个', '世', '界', '。', '[SEP]']\n"
     ]
    }
   ],
   "source": [
    "# 将input_ids转化回token\n",
    "\n",
    "print(tokenizer.convert_ids_to_tokens(tokenizer.encode('我不喜欢这个世界。')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 11])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 将分词输入模型，得到编码\n",
    "torch.tensor([a.input_ids]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([11])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(a.input_ids).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens_tensor = torch.tensor([a.input_ids])\n",
    "sagment_tensors = torch.tensor([a.token_type_ids])\n",
    "sagment_tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[[5.8265e-04, 9.1112e-04, 2.0561e-03,  ..., 1.0617e-03,\n",
       "            2.1599e-03, 9.8682e-01],\n",
       "           [4.0710e-02, 1.4153e-01, 4.1808e-02,  ..., 1.2148e-01,\n",
       "            8.3455e-02, 9.3920e-03],\n",
       "           [1.6007e-01, 7.0425e-02, 5.5830e-02,  ..., 1.0093e-01,\n",
       "            8.9538e-02, 1.0958e-02],\n",
       "           ...,\n",
       "           [1.5883e-01, 1.2269e-01, 1.5134e-02,  ..., 8.6266e-02,\n",
       "            1.5416e-01, 1.2672e-02],\n",
       "           [3.0713e-01, 4.7508e-02, 6.3705e-02,  ..., 4.1128e-02,\n",
       "            2.1358e-01, 2.9280e-02],\n",
       "           [8.6614e-01, 9.8779e-03, 1.4715e-02,  ..., 8.4041e-03,\n",
       "            1.4768e-02, 8.6476e-03]],\n",
       " \n",
       "          [[1.2658e-02, 3.2177e-02, 1.6318e-02,  ..., 3.3708e-02,\n",
       "            2.6675e-02, 8.4058e-01],\n",
       "           [4.2186e-01, 8.2696e-02, 2.0308e-01,  ..., 2.7415e-02,\n",
       "            1.4561e-02, 9.0180e-02],\n",
       "           [2.3303e-01, 3.6908e-01, 1.5277e-02,  ..., 4.4839e-03,\n",
       "            1.5576e-02, 6.0964e-03],\n",
       "           ...,\n",
       "           [1.2024e-02, 8.2655e-04, 8.6031e-04,  ..., 3.3744e-03,\n",
       "            4.6452e-02, 1.6852e-02],\n",
       "           [8.5058e-03, 3.8829e-03, 6.0515e-03,  ..., 3.3576e-01,\n",
       "            5.0303e-02, 5.5128e-01],\n",
       "           [7.4744e-04, 5.6165e-06, 6.6605e-07,  ..., 7.0423e-06,\n",
       "            6.1886e-05, 9.9917e-01]],\n",
       " \n",
       "          [[8.4726e-01, 9.9762e-03, 1.1855e-02,  ..., 2.0175e-02,\n",
       "            1.7027e-02, 2.1964e-02],\n",
       "           [7.2201e-01, 1.5488e-01, 9.7030e-03,  ..., 1.1251e-02,\n",
       "            1.9820e-02, 3.2769e-02],\n",
       "           [7.9289e-01, 1.6296e-02, 1.0080e-01,  ..., 5.3265e-03,\n",
       "            1.0233e-02, 1.7711e-02],\n",
       "           ...,\n",
       "           [5.5017e-01, 4.8253e-02, 2.0450e-02,  ..., 7.9898e-02,\n",
       "            1.0717e-02, 1.0848e-02],\n",
       "           [2.2547e-01, 8.9387e-02, 9.6256e-02,  ..., 2.1704e-02,\n",
       "            1.1152e-01, 1.9953e-02],\n",
       "           [7.6795e-01, 2.5098e-02, 3.6836e-02,  ..., 1.5483e-02,\n",
       "            5.5688e-03, 6.5987e-04]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[9.8098e-01, 8.1401e-04, 4.4526e-04,  ..., 9.2865e-04,\n",
       "            1.6470e-03, 8.6849e-03],\n",
       "           [9.3223e-02, 3.4962e-01, 5.1449e-02,  ..., 8.6220e-02,\n",
       "            3.2333e-02, 3.4670e-02],\n",
       "           [2.1178e-01, 5.8984e-02, 3.1747e-02,  ..., 1.2186e-01,\n",
       "            8.4102e-02, 1.0289e-01],\n",
       "           ...,\n",
       "           [3.3267e-01, 9.4768e-02, 5.2014e-02,  ..., 6.9295e-02,\n",
       "            1.2014e-01, 3.6195e-02],\n",
       "           [1.6345e-01, 7.9592e-02, 4.8889e-02,  ..., 3.8987e-02,\n",
       "            2.6334e-01, 4.3318e-02],\n",
       "           [6.9764e-01, 1.0856e-03, 1.1714e-03,  ..., 2.2737e-03,\n",
       "            1.5322e-03, 2.8414e-01]],\n",
       " \n",
       "          [[9.6767e-01, 9.6266e-04, 1.1609e-03,  ..., 7.5810e-03,\n",
       "            3.6948e-03, 6.2057e-03],\n",
       "           [2.2448e-02, 3.2296e-02, 1.5181e-01,  ..., 4.0828e-02,\n",
       "            1.8574e-02, 5.5266e-02],\n",
       "           [5.4882e-02, 1.4438e-01, 7.8905e-02,  ..., 4.7067e-02,\n",
       "            5.1019e-02, 1.1085e-01],\n",
       "           ...,\n",
       "           [2.6299e-02, 2.3795e-02, 2.2967e-02,  ..., 3.0398e-02,\n",
       "            1.6131e-01, 3.4329e-01],\n",
       "           [2.3292e-03, 1.1450e-02, 9.7379e-03,  ..., 5.7280e-02,\n",
       "            9.3738e-02, 6.3273e-01],\n",
       "           [7.2479e-01, 5.5980e-04, 1.2952e-03,  ..., 3.7824e-02,\n",
       "            4.1561e-02, 1.7433e-01]],\n",
       " \n",
       "          [[9.5174e-01, 5.6350e-03, 5.6974e-03,  ..., 3.9745e-03,\n",
       "            6.4003e-03, 5.0070e-03],\n",
       "           [1.2852e-01, 5.7070e-02, 2.6681e-01,  ..., 4.9613e-02,\n",
       "            4.2590e-02, 5.1822e-02],\n",
       "           [6.1445e-02, 2.0779e-01, 6.1383e-02,  ..., 2.3924e-02,\n",
       "            2.4219e-02, 2.4514e-02],\n",
       "           ...,\n",
       "           [4.4037e-02, 1.4388e-02, 2.2867e-02,  ..., 5.0922e-02,\n",
       "            1.2594e-01, 2.3352e-01],\n",
       "           [1.7519e-01, 9.2378e-03, 6.6220e-03,  ..., 1.1628e-01,\n",
       "            9.5000e-02, 4.6483e-01],\n",
       "           [3.0944e-01, 8.0587e-04, 7.3927e-04,  ..., 6.0275e-03,\n",
       "            6.2987e-01, 3.9333e-02]]]]),\n",
       " tensor([[[[7.4213e-01, 1.9779e-02, 8.8652e-03,  ..., 9.4743e-03,\n",
       "            6.7210e-02, 1.0044e-01],\n",
       "           [9.7839e-01, 2.2118e-03, 1.8724e-03,  ..., 3.2394e-05,\n",
       "            1.3406e-04, 1.4749e-02],\n",
       "           [6.9490e-02, 9.3023e-01, 3.6399e-05,  ..., 2.2089e-07,\n",
       "            1.3525e-04, 5.4060e-06],\n",
       "           ...,\n",
       "           [4.1625e-02, 8.0432e-05, 1.0712e-06,  ..., 2.3733e-04,\n",
       "            2.4241e-02, 2.3191e-02],\n",
       "           [6.7671e-01, 1.2804e-04, 2.0342e-04,  ..., 8.2492e-02,\n",
       "            3.0762e-02, 1.9140e-01],\n",
       "           [7.3317e-01, 8.4708e-05, 2.4887e-06,  ..., 7.9335e-05,\n",
       "            2.5630e-01, 9.1653e-03]],\n",
       " \n",
       "          [[1.9974e-01, 6.7715e-02, 5.6077e-02,  ..., 6.8456e-02,\n",
       "            6.0698e-02, 1.0122e-01],\n",
       "           [7.2081e-02, 7.9814e-04, 2.6233e-02,  ..., 1.0468e-01,\n",
       "            6.1253e-02, 4.5315e-02],\n",
       "           [1.1731e-01, 1.2615e-01, 1.9560e-02,  ..., 2.9529e-02,\n",
       "            1.8986e-02, 8.9070e-02],\n",
       "           ...,\n",
       "           [8.1240e-02, 4.2295e-02, 6.2987e-02,  ..., 3.1741e-03,\n",
       "            1.8484e-02, 2.6963e-02],\n",
       "           [1.3465e-01, 1.0627e-01, 3.4617e-02,  ..., 6.2698e-02,\n",
       "            1.1508e-01, 1.6980e-01],\n",
       "           [1.1073e-01, 7.1956e-02, 3.8582e-02,  ..., 5.8066e-02,\n",
       "            7.6969e-02, 2.8744e-01]],\n",
       " \n",
       "          [[9.1414e-01, 4.8106e-03, 5.3084e-03,  ..., 1.2395e-02,\n",
       "            6.5588e-03, 3.0950e-02],\n",
       "           [2.1773e-01, 6.7694e-01, 8.1914e-03,  ..., 3.0667e-03,\n",
       "            1.5036e-02, 4.4329e-02],\n",
       "           [5.8034e-01, 5.0710e-02, 1.1554e-01,  ..., 4.6991e-03,\n",
       "            1.8834e-02, 6.8526e-02],\n",
       "           ...,\n",
       "           [1.8418e-01, 4.7633e-03, 3.7864e-03,  ..., 2.0820e-02,\n",
       "            2.9178e-02, 8.2899e-02],\n",
       "           [6.9846e-01, 9.7839e-02, 2.8809e-02,  ..., 2.1467e-02,\n",
       "            1.9137e-02, 6.6493e-02],\n",
       "           [9.1579e-01, 5.2775e-03, 6.8065e-03,  ..., 1.0266e-02,\n",
       "            5.2331e-03, 2.0830e-02]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[9.4266e-01, 1.3603e-03, 9.4949e-04,  ..., 3.7684e-03,\n",
       "            1.3342e-02, 2.4877e-02],\n",
       "           [1.2969e-01, 4.0498e-02, 1.7173e-02,  ..., 3.8523e-02,\n",
       "            1.3630e-01, 1.6220e-01],\n",
       "           [2.0249e-01, 1.1375e-03, 6.7633e-02,  ..., 4.0807e-02,\n",
       "            2.1544e-01, 1.4870e-01],\n",
       "           ...,\n",
       "           [8.5882e-01, 2.7375e-04, 2.0645e-04,  ..., 5.0203e-02,\n",
       "            1.5960e-02, 4.5947e-02],\n",
       "           [5.8920e-01, 5.7324e-03, 3.5209e-03,  ..., 1.7784e-02,\n",
       "            6.2957e-02, 2.5242e-01],\n",
       "           [9.8622e-01, 5.5984e-05, 4.3504e-05,  ..., 4.9652e-04,\n",
       "            3.1469e-03, 8.6977e-03]],\n",
       " \n",
       "          [[9.1551e-01, 8.0472e-03, 8.8605e-03,  ..., 5.8934e-03,\n",
       "            7.8170e-03, 1.7013e-02],\n",
       "           [2.7913e-01, 2.5469e-02, 1.8379e-01,  ..., 7.2407e-03,\n",
       "            3.6117e-02, 4.0003e-01],\n",
       "           [7.0158e-01, 8.1594e-03, 5.2049e-03,  ..., 5.3911e-02,\n",
       "            2.2049e-02, 7.6933e-02],\n",
       "           ...,\n",
       "           [5.6221e-01, 3.1028e-02, 4.7674e-02,  ..., 6.6112e-03,\n",
       "            5.8791e-02, 1.2674e-01],\n",
       "           [3.5346e-02, 1.0060e-01, 9.2649e-02,  ..., 8.6535e-02,\n",
       "            9.7633e-02, 2.9390e-01],\n",
       "           [1.5817e-02, 1.9550e-02, 2.8641e-02,  ..., 9.6946e-02,\n",
       "            3.9811e-02, 2.3221e-01]],\n",
       " \n",
       "          [[9.6495e-01, 5.7267e-03, 3.7661e-03,  ..., 1.7403e-03,\n",
       "            6.6328e-03, 8.8342e-03],\n",
       "           [4.4704e-01, 1.7067e-02, 2.4784e-02,  ..., 4.9653e-02,\n",
       "            1.6228e-01, 1.4680e-02],\n",
       "           [8.1738e-01, 6.7186e-03, 5.2473e-03,  ..., 4.8979e-03,\n",
       "            6.0080e-02, 1.7077e-02],\n",
       "           ...,\n",
       "           [2.7620e-01, 2.5094e-02, 2.5556e-02,  ..., 5.6588e-02,\n",
       "            3.4655e-01, 4.0999e-02],\n",
       "           [4.1096e-01, 1.0597e-01, 4.1919e-02,  ..., 2.5279e-02,\n",
       "            8.1115e-02, 3.6123e-02],\n",
       "           [8.6719e-01, 3.1638e-02, 1.3636e-02,  ..., 2.9404e-03,\n",
       "            3.2945e-02, 3.1413e-02]]]]),\n",
       " tensor([[[[7.7345e-01, 2.1804e-03, 2.1314e-03,  ..., 3.8424e-03,\n",
       "            1.4478e-02, 1.8968e-01],\n",
       "           [1.0953e-01, 1.2437e-01, 5.5284e-02,  ..., 2.3666e-02,\n",
       "            1.4047e-01, 1.0729e-01],\n",
       "           [3.6277e-01, 1.3167e-01, 8.5571e-02,  ..., 3.4680e-02,\n",
       "            3.9628e-02, 3.8978e-02],\n",
       "           ...,\n",
       "           [2.4987e-01, 4.0809e-02, 1.8726e-02,  ..., 6.4339e-02,\n",
       "            5.8167e-02, 3.1086e-01],\n",
       "           [1.3391e-01, 1.1530e-01, 3.9718e-02,  ..., 8.8835e-03,\n",
       "            2.2148e-01, 2.0703e-01],\n",
       "           [7.7570e-01, 4.1669e-03, 3.6756e-03,  ..., 5.6382e-03,\n",
       "            2.0484e-02, 1.6976e-01]],\n",
       " \n",
       "          [[9.2525e-01, 1.8306e-03, 1.8089e-03,  ..., 4.7778e-04,\n",
       "            2.1926e-02, 4.0531e-02],\n",
       "           [6.2850e-01, 6.0416e-03, 1.2942e-02,  ..., 3.4988e-04,\n",
       "            4.6275e-02, 2.2830e-01],\n",
       "           [5.6488e-01, 1.2413e-02, 3.3570e-03,  ..., 3.7842e-05,\n",
       "            6.9407e-02, 1.7291e-01],\n",
       "           ...,\n",
       "           [8.6190e-01, 4.3333e-04, 6.6537e-05,  ..., 1.9333e-04,\n",
       "            2.8549e-02, 1.3208e-02],\n",
       "           [8.9714e-01, 1.7861e-04, 1.3482e-04,  ..., 2.4988e-04,\n",
       "            3.6339e-02, 6.4602e-02],\n",
       "           [8.3724e-01, 4.7899e-03, 1.2757e-02,  ..., 1.2176e-02,\n",
       "            5.3066e-02, 4.2022e-02]],\n",
       " \n",
       "          [[4.3602e-01, 9.2480e-04, 1.3839e-03,  ..., 1.8218e-04,\n",
       "            3.6920e-03, 5.5094e-01],\n",
       "           [4.5696e-01, 3.5907e-02, 1.8260e-02,  ..., 1.5089e-03,\n",
       "            6.2577e-02, 3.0083e-01],\n",
       "           [7.1580e-01, 1.7962e-02, 6.2029e-03,  ..., 6.6066e-04,\n",
       "            3.8021e-02, 1.7363e-01],\n",
       "           ...,\n",
       "           [6.4493e-01, 5.0461e-02, 7.7414e-03,  ..., 2.3147e-02,\n",
       "            3.5404e-02, 7.9782e-02],\n",
       "           [2.1576e-01, 1.3631e-01, 5.1299e-02,  ..., 3.3695e-04,\n",
       "            3.4482e-02, 4.8116e-01],\n",
       "           [6.3238e-01, 1.4320e-03, 1.3581e-03,  ..., 2.6956e-04,\n",
       "            5.5298e-03, 3.5242e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[8.4458e-01, 6.7168e-03, 1.9118e-03,  ..., 1.1942e-02,\n",
       "            3.5156e-02, 7.4631e-02],\n",
       "           [1.1179e-01, 5.2809e-02, 1.3990e-02,  ..., 2.8438e-02,\n",
       "            2.4978e-02, 4.1102e-02],\n",
       "           [1.1512e-01, 1.7406e-02, 1.6032e-02,  ..., 8.9414e-03,\n",
       "            2.6523e-02, 3.7550e-02],\n",
       "           ...,\n",
       "           [4.1661e-01, 6.6635e-05, 9.0089e-05,  ..., 5.0256e-02,\n",
       "            3.5289e-01, 1.6404e-01],\n",
       "           [8.1885e-01, 3.3152e-03, 1.8841e-04,  ..., 2.7067e-02,\n",
       "            5.0479e-02, 9.4408e-02],\n",
       "           [6.9042e-01, 1.1937e-02, 4.9420e-03,  ..., 1.8247e-02,\n",
       "            1.0278e-01, 1.3158e-01]],\n",
       " \n",
       "          [[9.0165e-01, 5.5888e-03, 1.9745e-03,  ..., 1.7557e-03,\n",
       "            1.2981e-02, 5.6110e-02],\n",
       "           [8.2695e-01, 7.4296e-02, 1.8613e-03,  ..., 3.6269e-05,\n",
       "            5.3839e-03, 8.9200e-02],\n",
       "           [8.8101e-01, 2.7948e-02, 2.8882e-02,  ..., 6.5409e-05,\n",
       "            1.6495e-03, 5.4734e-02],\n",
       "           ...,\n",
       "           [2.1239e-02, 1.5963e-02, 5.4522e-03,  ..., 1.0731e-02,\n",
       "            1.9439e-02, 2.0974e-02],\n",
       "           [1.2300e-01, 2.0685e-02, 1.8065e-02,  ..., 1.0602e-01,\n",
       "            6.9900e-02, 4.5608e-02],\n",
       "           [7.8517e-01, 8.2973e-03, 3.4649e-03,  ..., 1.1153e-02,\n",
       "            4.4424e-02, 1.0618e-01]],\n",
       " \n",
       "          [[8.9275e-01, 5.4994e-03, 5.9285e-03,  ..., 3.2088e-03,\n",
       "            2.5811e-02, 5.0282e-02],\n",
       "           [9.1477e-01, 1.5956e-03, 1.7411e-02,  ..., 6.9791e-04,\n",
       "            1.0076e-03, 5.5806e-02],\n",
       "           [5.8427e-01, 2.3472e-03, 4.7909e-04,  ..., 9.3049e-05,\n",
       "            6.8830e-03, 6.1213e-02],\n",
       "           ...,\n",
       "           [8.6436e-01, 3.0011e-04, 1.3113e-05,  ..., 2.6993e-03,\n",
       "            9.1813e-02, 3.1559e-02],\n",
       "           [8.7072e-01, 1.6958e-04, 2.6207e-04,  ..., 1.6537e-03,\n",
       "            2.8145e-02, 9.7295e-02],\n",
       "           [3.2218e-01, 9.7404e-03, 2.2212e-03,  ..., 7.3599e-03,\n",
       "            2.0854e-01, 4.3696e-01]]]]),\n",
       " tensor([[[[6.0756e-02, 4.0039e-03, 1.2595e-02,  ..., 8.3746e-03,\n",
       "            1.8545e-02, 8.5704e-01],\n",
       "           [7.2980e-02, 4.6851e-02, 2.3594e-01,  ..., 3.7308e-02,\n",
       "            1.6483e-02, 6.2145e-02],\n",
       "           [1.3500e-01, 1.1806e-01, 5.9242e-02,  ..., 7.1290e-03,\n",
       "            1.5792e-02, 1.1717e-01],\n",
       "           ...,\n",
       "           [4.4923e-02, 4.3451e-02, 1.1712e-01,  ..., 1.7786e-01,\n",
       "            1.3705e-02, 1.1709e-01],\n",
       "           [7.0802e-02, 1.4408e-01, 3.6003e-01,  ..., 3.7578e-02,\n",
       "            8.3004e-03, 1.0196e-01],\n",
       "           [5.0935e-03, 2.4413e-04, 3.7584e-04,  ..., 2.9266e-04,\n",
       "            1.5068e-03, 9.9105e-01]],\n",
       " \n",
       "          [[1.2696e-01, 1.8244e-01, 2.5174e-02,  ..., 2.9209e-02,\n",
       "            2.6506e-01, 1.9668e-01],\n",
       "           [1.2479e-01, 9.6524e-02, 9.4073e-02,  ..., 5.2946e-02,\n",
       "            3.0430e-02, 2.3666e-01],\n",
       "           [1.0945e-01, 4.1092e-02, 1.5893e-01,  ..., 2.4688e-02,\n",
       "            2.4079e-02, 3.3803e-01],\n",
       "           ...,\n",
       "           [1.2420e-01, 4.1507e-02, 7.9473e-02,  ..., 6.5012e-02,\n",
       "            2.0753e-02, 3.4907e-01],\n",
       "           [1.0696e-01, 1.2765e-01, 4.3438e-02,  ..., 1.3644e-02,\n",
       "            1.3304e-01, 2.0343e-01],\n",
       "           [9.2650e-02, 5.1111e-03, 4.0444e-03,  ..., 2.5508e-03,\n",
       "            3.4679e-02, 8.4711e-01]],\n",
       " \n",
       "          [[2.4681e-01, 2.4853e-02, 2.5163e-02,  ..., 3.4345e-02,\n",
       "            4.1246e-01, 1.5279e-01],\n",
       "           [2.9757e-01, 3.4525e-01, 2.7355e-02,  ..., 6.1369e-03,\n",
       "            1.4589e-02, 2.7045e-01],\n",
       "           [3.6008e-01, 7.1591e-03, 3.4408e-01,  ..., 8.6886e-04,\n",
       "            4.2621e-02, 2.1295e-01],\n",
       "           ...,\n",
       "           [1.6899e-01, 1.6007e-03, 8.0588e-04,  ..., 4.4106e-01,\n",
       "            1.4657e-02, 1.2570e-01],\n",
       "           [3.5989e-01, 4.1389e-03, 4.6504e-03,  ..., 1.0264e-02,\n",
       "            4.3562e-01, 1.6806e-01],\n",
       "           [3.3764e-01, 3.9070e-02, 3.0599e-02,  ..., 2.7892e-02,\n",
       "            2.7809e-01, 1.8573e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[1.0006e-01, 1.5330e-02, 6.6883e-03,  ..., 9.7808e-03,\n",
       "            2.5415e-02, 8.1450e-01],\n",
       "           [8.6900e-02, 4.5188e-02, 3.1874e-02,  ..., 5.0071e-02,\n",
       "            8.7674e-02, 6.2737e-01],\n",
       "           [5.6755e-02, 1.5774e-01, 6.0674e-02,  ..., 4.9333e-02,\n",
       "            9.3025e-02, 4.3898e-01],\n",
       "           ...,\n",
       "           [5.2943e-02, 1.6844e-01, 6.9111e-02,  ..., 3.9004e-02,\n",
       "            3.0777e-02, 8.5635e-02],\n",
       "           [6.6335e-02, 1.1023e-01, 1.0967e-01,  ..., 8.5245e-02,\n",
       "            8.2720e-02, 1.2277e-01],\n",
       "           [3.2934e-02, 4.7146e-03, 4.2651e-03,  ..., 5.6134e-03,\n",
       "            5.3525e-03, 9.3020e-01]],\n",
       " \n",
       "          [[5.6662e-02, 1.7664e-03, 1.4467e-03,  ..., 2.3995e-04,\n",
       "            1.0127e-02, 9.2632e-01],\n",
       "           [1.2161e-01, 1.8493e-01, 6.0263e-04,  ..., 3.7663e-04,\n",
       "            4.2193e-02, 6.4715e-01],\n",
       "           [1.1337e-01, 1.8226e-03, 6.4184e-02,  ..., 1.9637e-05,\n",
       "            1.2611e-02, 8.0702e-01],\n",
       "           ...,\n",
       "           [2.0029e-01, 1.4747e-03, 2.0259e-04,  ..., 1.4742e-01,\n",
       "            1.7058e-02, 6.1240e-01],\n",
       "           [1.3130e-01, 2.7631e-03, 1.1774e-03,  ..., 4.1456e-04,\n",
       "            1.6367e-01, 6.9521e-01],\n",
       "           [2.3901e-02, 3.8712e-04, 3.4475e-04,  ..., 1.7574e-04,\n",
       "            1.6312e-03, 9.7187e-01]],\n",
       " \n",
       "          [[9.6660e-02, 4.5211e-03, 2.6063e-03,  ..., 7.6078e-03,\n",
       "            3.1943e-02, 8.4001e-01],\n",
       "           [5.7286e-02, 1.1658e-02, 2.8670e-02,  ..., 8.1912e-02,\n",
       "            2.7395e-01, 2.7995e-01],\n",
       "           [4.3483e-02, 1.0801e-02, 2.9869e-02,  ..., 6.3313e-02,\n",
       "            5.8157e-01, 8.0742e-02],\n",
       "           ...,\n",
       "           [1.2861e-01, 3.0619e-03, 2.0411e-03,  ..., 7.0405e-03,\n",
       "            1.0127e-01, 5.0688e-01],\n",
       "           [1.2359e-01, 4.6904e-03, 2.7908e-03,  ..., 5.8303e-03,\n",
       "            3.6589e-02, 8.0884e-01],\n",
       "           [3.9493e-02, 2.8737e-03, 1.4380e-03,  ..., 4.5220e-03,\n",
       "            1.2111e-02, 9.2796e-01]]]]),\n",
       " tensor([[[[1.4938e-01, 1.5674e-01, 1.1908e-01,  ..., 1.7875e-02,\n",
       "            9.7207e-02, 2.8894e-01],\n",
       "           [5.0203e-02, 9.5543e-02, 2.5514e-01,  ..., 3.0747e-02,\n",
       "            1.3743e-01, 7.6890e-02],\n",
       "           [1.0038e-01, 7.0482e-02, 1.6811e-01,  ..., 4.6476e-02,\n",
       "            1.0593e-01, 2.3733e-01],\n",
       "           ...,\n",
       "           [7.8478e-02, 6.2012e-02, 6.9127e-02,  ..., 8.1370e-02,\n",
       "            9.3619e-02, 2.3836e-01],\n",
       "           [8.2033e-02, 1.0415e-01, 1.0248e-01,  ..., 6.5562e-02,\n",
       "            8.3997e-02, 1.3504e-01],\n",
       "           [5.2150e-02, 1.1055e-03, 6.4708e-04,  ..., 1.3054e-04,\n",
       "            2.7491e-03, 9.4201e-01]],\n",
       " \n",
       "          [[2.7439e-01, 2.9049e-02, 3.8410e-02,  ..., 6.4104e-03,\n",
       "            1.3764e-01, 4.3747e-01],\n",
       "           [4.1498e-01, 1.8722e-02, 1.7410e-02,  ..., 5.0460e-03,\n",
       "            5.1643e-02, 4.5263e-01],\n",
       "           [1.8573e-01, 1.3357e-02, 9.9159e-03,  ..., 1.2983e-03,\n",
       "            3.4508e-02, 7.2222e-01],\n",
       "           ...,\n",
       "           [3.5874e-01, 1.1097e-02, 3.4625e-03,  ..., 1.6824e-02,\n",
       "            2.8873e-02, 5.1506e-01],\n",
       "           [4.4442e-01, 1.5224e-02, 1.5565e-02,  ..., 2.8082e-03,\n",
       "            5.9981e-02, 4.2518e-01],\n",
       "           [1.5890e-02, 2.3787e-03, 2.5292e-03,  ..., 1.9744e-04,\n",
       "            2.4200e-03, 9.7171e-01]],\n",
       " \n",
       "          [[8.9293e-02, 2.4668e-02, 4.5901e-03,  ..., 1.2028e-02,\n",
       "            8.5773e-02, 7.6679e-01],\n",
       "           [8.5423e-02, 7.4188e-03, 1.6015e-05,  ..., 7.5227e-07,\n",
       "            3.0971e-05, 9.0710e-01],\n",
       "           [1.1428e-01, 6.8490e-06, 2.5022e-02,  ..., 3.1694e-08,\n",
       "            5.5964e-06, 8.6069e-01],\n",
       "           ...,\n",
       "           [4.9422e-02, 2.0548e-06, 1.4047e-07,  ..., 1.2671e-02,\n",
       "            3.0833e-04, 9.3705e-01],\n",
       "           [6.9782e-02, 2.1471e-05, 1.8068e-06,  ..., 4.6186e-05,\n",
       "            2.8083e-02, 9.0204e-01],\n",
       "           [1.9691e-02, 2.8517e-04, 1.0694e-04,  ..., 1.3865e-04,\n",
       "            3.8411e-03, 9.7528e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[1.1904e-01, 1.6895e-01, 8.6162e-02,  ..., 7.3858e-02,\n",
       "            1.8208e-01, 1.0671e-01],\n",
       "           [1.6424e-02, 1.6163e-02, 9.5162e-02,  ..., 1.9090e-02,\n",
       "            1.8231e-02, 1.5493e-02],\n",
       "           [4.4656e-02, 1.3265e-02, 8.5596e-02,  ..., 2.4277e-02,\n",
       "            3.2108e-02, 6.4767e-02],\n",
       "           ...,\n",
       "           [1.6423e-01, 1.0988e-02, 4.0717e-02,  ..., 1.0344e-01,\n",
       "            3.4921e-01, 1.4597e-01],\n",
       "           [7.0852e-02, 8.1099e-02, 2.8068e-01,  ..., 7.0817e-02,\n",
       "            1.0972e-01, 6.6824e-02],\n",
       "           [2.0435e-01, 1.0083e-01, 6.3386e-02,  ..., 4.5982e-02,\n",
       "            1.8178e-01, 1.8028e-01]],\n",
       " \n",
       "          [[2.0764e-02, 9.2031e-03, 7.0156e-03,  ..., 5.9633e-03,\n",
       "            9.2491e-03, 9.1710e-01],\n",
       "           [2.8639e-02, 2.0850e-02, 7.6303e-02,  ..., 6.7093e-03,\n",
       "            1.4127e-02, 7.6608e-01],\n",
       "           [6.4703e-02, 1.2876e-01, 1.2007e-02,  ..., 7.7158e-03,\n",
       "            1.7730e-02, 6.7252e-01],\n",
       "           ...,\n",
       "           [1.1499e-01, 5.0175e-03, 4.5210e-02,  ..., 5.2087e-03,\n",
       "            2.3939e-02, 2.9329e-01],\n",
       "           [5.1189e-02, 3.3824e-02, 4.1013e-02,  ..., 5.0991e-02,\n",
       "            2.1022e-02, 4.7212e-01],\n",
       "           [8.7866e-04, 3.2103e-04, 1.7637e-04,  ..., 7.9234e-04,\n",
       "            2.0710e-04, 9.9365e-01]],\n",
       " \n",
       "          [[6.5319e-02, 2.8418e-02, 9.2429e-03,  ..., 1.7858e-02,\n",
       "            6.0055e-01, 1.7415e-01],\n",
       "           [9.1809e-02, 5.2044e-02, 5.1900e-02,  ..., 8.4531e-02,\n",
       "            1.1334e-01, 2.1012e-01],\n",
       "           [6.1986e-02, 1.5159e-02, 1.2173e-02,  ..., 1.5351e-01,\n",
       "            1.9098e-01, 8.0416e-02],\n",
       "           ...,\n",
       "           [9.2594e-02, 5.9201e-02, 3.3482e-02,  ..., 1.1815e-02,\n",
       "            6.6536e-02, 4.0689e-01],\n",
       "           [1.0397e-01, 1.0152e-01, 4.2052e-02,  ..., 6.6533e-02,\n",
       "            6.9429e-02, 3.5408e-01],\n",
       "           [1.8161e-02, 2.4910e-03, 5.2233e-04,  ..., 1.6413e-03,\n",
       "            2.3386e-02, 9.4793e-01]]]]),\n",
       " tensor([[[[2.9433e-03, 5.4569e-03, 3.5281e-03,  ..., 1.1269e-02,\n",
       "            2.9595e-02, 9.0259e-01],\n",
       "           [9.2738e-02, 2.1591e-01, 2.4411e-03,  ..., 1.9846e-02,\n",
       "            8.3071e-02, 5.3224e-01],\n",
       "           [1.8678e-01, 3.1110e-03, 5.4866e-02,  ..., 9.4275e-04,\n",
       "            9.4659e-02, 5.8897e-01],\n",
       "           ...,\n",
       "           [3.7948e-02, 2.5531e-03, 2.5825e-04,  ..., 2.4970e-01,\n",
       "            3.0565e-02, 3.6817e-01],\n",
       "           [2.1808e-02, 2.4673e-02, 3.5553e-03,  ..., 3.2936e-02,\n",
       "            2.1038e-01, 5.9820e-01],\n",
       "           [6.4517e-04, 2.9876e-03, 1.7011e-03,  ..., 1.7889e-03,\n",
       "            5.1533e-03, 9.7622e-01]],\n",
       " \n",
       "          [[2.7359e-01, 3.4085e-02, 1.3417e-02,  ..., 1.3071e-02,\n",
       "            5.2226e-02, 5.3799e-01],\n",
       "           [6.7740e-02, 1.6807e-01, 1.1468e-01,  ..., 2.7274e-02,\n",
       "            2.6676e-01, 2.2753e-01],\n",
       "           [1.2133e-01, 1.5782e-01, 2.1905e-02,  ..., 9.6399e-03,\n",
       "            1.9121e-01, 3.7870e-01],\n",
       "           ...,\n",
       "           [1.3812e-01, 6.8625e-02, 6.6440e-02,  ..., 1.6319e-02,\n",
       "            1.8750e-01, 2.3562e-01],\n",
       "           [7.4392e-02, 1.0701e-01, 6.3763e-02,  ..., 2.7133e-02,\n",
       "            2.3126e-01, 3.4683e-01],\n",
       "           [3.1303e-02, 1.2245e-02, 1.8599e-02,  ..., 2.4654e-02,\n",
       "            1.6683e-02, 8.2377e-01]],\n",
       " \n",
       "          [[9.9447e-02, 2.5788e-01, 1.2334e-02,  ..., 5.8142e-02,\n",
       "            1.4919e-01, 2.7684e-01],\n",
       "           [2.3533e-01, 1.4990e-01, 1.2417e-02,  ..., 6.9966e-02,\n",
       "            1.5347e-01, 1.6039e-01],\n",
       "           [1.2610e-01, 3.9854e-02, 5.8748e-02,  ..., 3.9766e-02,\n",
       "            1.2821e-01, 4.5817e-01],\n",
       "           ...,\n",
       "           [1.4265e-01, 6.3506e-02, 1.1632e-02,  ..., 1.3764e-01,\n",
       "            1.1648e-01, 2.7052e-01],\n",
       "           [1.5941e-01, 7.7105e-02, 1.2875e-02,  ..., 1.6469e-01,\n",
       "            7.3914e-02, 2.3047e-01],\n",
       "           [1.0671e-03, 9.8312e-05, 3.9683e-05,  ..., 9.7167e-05,\n",
       "            2.1840e-04, 9.9826e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[9.2803e-02, 8.2309e-02, 3.2740e-02,  ..., 9.6381e-03,\n",
       "            1.4495e-02, 6.9403e-01],\n",
       "           [7.0803e-02, 1.7023e-02, 1.2081e-01,  ..., 4.8462e-02,\n",
       "            3.3650e-02, 3.3321e-01],\n",
       "           [3.9854e-02, 1.6372e-02, 5.2987e-02,  ..., 8.7424e-02,\n",
       "            9.1805e-02, 1.4675e-01],\n",
       "           ...,\n",
       "           [2.4622e-02, 5.0130e-03, 5.9554e-03,  ..., 5.8828e-02,\n",
       "            1.4979e-01, 6.4812e-01],\n",
       "           [4.3193e-02, 2.6154e-02, 1.2959e-02,  ..., 3.4853e-02,\n",
       "            7.6508e-02, 7.1093e-01],\n",
       "           [3.1956e-03, 4.2348e-03, 3.2763e-03,  ..., 3.8861e-03,\n",
       "            8.9203e-03, 9.5240e-01]],\n",
       " \n",
       "          [[3.4783e-02, 7.5354e-02, 2.5074e-02,  ..., 1.8107e-02,\n",
       "            4.8459e-02, 7.2421e-01],\n",
       "           [8.2907e-02, 2.3969e-02, 1.3680e-01,  ..., 7.2685e-03,\n",
       "            1.6868e-02, 6.2130e-01],\n",
       "           [1.5139e-01, 1.8230e-03, 1.6075e-03,  ..., 4.8963e-03,\n",
       "            3.8035e-02, 1.3726e-01],\n",
       "           ...,\n",
       "           [1.4007e-02, 1.1338e-03, 1.4971e-04,  ..., 9.5336e-02,\n",
       "            5.9078e-02, 6.0884e-01],\n",
       "           [3.5094e-02, 7.2218e-02, 1.0172e-02,  ..., 3.2729e-02,\n",
       "            6.5072e-02, 6.8753e-01],\n",
       "           [8.5140e-03, 1.5259e-02, 7.8413e-03,  ..., 1.3088e-02,\n",
       "            1.3813e-02, 9.1041e-01]],\n",
       " \n",
       "          [[3.7152e-02, 1.6088e-02, 2.6637e-02,  ..., 1.9784e-02,\n",
       "            2.3110e-02, 7.8831e-01],\n",
       "           [1.6463e-02, 2.6077e-03, 1.6184e-03,  ..., 1.9301e-03,\n",
       "            1.8334e-02, 9.3535e-01],\n",
       "           [4.4594e-02, 9.6570e-02, 3.8880e-03,  ..., 1.9893e-03,\n",
       "            3.9417e-02, 8.0166e-01],\n",
       "           ...,\n",
       "           [5.1973e-02, 1.8461e-03, 1.1323e-03,  ..., 7.5159e-03,\n",
       "            1.8797e-02, 7.5224e-01],\n",
       "           [5.0854e-02, 2.9006e-03, 4.7059e-03,  ..., 5.1578e-02,\n",
       "            5.6116e-02, 7.7733e-01],\n",
       "           [8.7838e-03, 8.1420e-03, 6.8808e-03,  ..., 5.8132e-03,\n",
       "            5.6785e-03, 9.2479e-01]]]]),\n",
       " tensor([[[[4.7195e-01, 2.4221e-01, 6.1235e-02,  ..., 1.9201e-02,\n",
       "            1.0298e-02, 7.5392e-02],\n",
       "           [1.0858e-01, 5.0893e-02, 1.1273e-01,  ..., 1.9612e-02,\n",
       "            5.2956e-02, 1.8993e-01],\n",
       "           [7.0767e-02, 2.7935e-02, 7.0482e-02,  ..., 3.9588e-02,\n",
       "            2.7498e-01, 2.6380e-01],\n",
       "           ...,\n",
       "           [3.2326e-02, 9.0765e-03, 1.2884e-02,  ..., 6.5079e-02,\n",
       "            2.3908e-01, 4.9464e-01],\n",
       "           [4.6895e-02, 3.7393e-02, 2.2190e-02,  ..., 2.1524e-02,\n",
       "            1.1026e-01, 6.9004e-01],\n",
       "           [9.5888e-03, 6.8826e-03, 3.0267e-03,  ..., 7.5581e-03,\n",
       "            2.7982e-02, 9.1846e-01]],\n",
       " \n",
       "          [[2.8023e-02, 2.0420e-02, 1.1227e-02,  ..., 4.9937e-03,\n",
       "            9.9221e-03, 8.9750e-01],\n",
       "           [4.4157e-02, 1.8703e-02, 1.0493e-02,  ..., 8.8646e-04,\n",
       "            9.7153e-03, 9.1054e-01],\n",
       "           [4.5157e-02, 1.0407e-01, 1.3847e-02,  ..., 2.1453e-03,\n",
       "            1.3894e-02, 7.9339e-01],\n",
       "           ...,\n",
       "           [1.5132e-01, 2.6528e-02, 5.3837e-02,  ..., 2.6279e-02,\n",
       "            4.4679e-02, 1.2576e-01],\n",
       "           [1.4253e-02, 9.7774e-03, 1.6858e-02,  ..., 1.4690e-02,\n",
       "            6.7549e-02, 8.1397e-01],\n",
       "           [2.4447e-03, 6.7378e-04, 1.9605e-03,  ..., 1.2215e-03,\n",
       "            4.0332e-03, 9.8362e-01]],\n",
       " \n",
       "          [[1.8172e-02, 1.7736e-02, 1.7684e-03,  ..., 7.4573e-03,\n",
       "            7.6281e-03, 8.8456e-01],\n",
       "           [3.5451e-02, 2.1785e-02, 2.0220e-02,  ..., 1.2997e-03,\n",
       "            2.0210e-03, 9.0207e-01],\n",
       "           [4.3978e-02, 4.7235e-03, 4.3068e-03,  ..., 7.5314e-04,\n",
       "            4.5136e-03, 5.4342e-01],\n",
       "           ...,\n",
       "           [7.8112e-03, 1.4110e-03, 5.9652e-04,  ..., 2.0323e-02,\n",
       "            1.3296e-02, 9.1801e-01],\n",
       "           [1.0803e-02, 3.7779e-03, 1.3699e-03,  ..., 5.8638e-03,\n",
       "            2.1491e-02, 9.4002e-01],\n",
       "           [6.9749e-03, 1.3843e-03, 1.7677e-03,  ..., 7.8041e-03,\n",
       "            8.3104e-03, 9.5223e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[2.2398e-02, 6.9662e-02, 5.1309e-02,  ..., 3.3973e-02,\n",
       "            6.5031e-03, 6.7629e-01],\n",
       "           [3.0438e-02, 1.6029e-02, 9.9785e-02,  ..., 6.6658e-03,\n",
       "            4.2595e-03, 3.5885e-01],\n",
       "           [8.5390e-02, 2.7659e-03, 4.7427e-02,  ..., 2.0296e-02,\n",
       "            6.4339e-03, 2.1843e-01],\n",
       "           ...,\n",
       "           [1.8720e-02, 1.5187e-03, 2.2278e-04,  ..., 9.9451e-03,\n",
       "            3.7842e-02, 9.1069e-01],\n",
       "           [5.5622e-03, 5.0101e-03, 2.5794e-03,  ..., 4.7942e-02,\n",
       "            6.0901e-03, 8.7231e-01],\n",
       "           [3.8370e-03, 1.2466e-02, 1.0558e-02,  ..., 1.4945e-02,\n",
       "            4.3779e-03, 9.1400e-01]],\n",
       " \n",
       "          [[8.8099e-02, 6.2178e-02, 3.1403e-02,  ..., 9.1403e-03,\n",
       "            4.6431e-02, 6.9260e-01],\n",
       "           [1.1767e-02, 5.1486e-02, 2.6530e-02,  ..., 1.0619e-02,\n",
       "            1.5739e-01, 6.9129e-01],\n",
       "           [4.5871e-02, 2.5546e-02, 2.4377e-02,  ..., 1.5509e-02,\n",
       "            3.2492e-01, 4.9497e-01],\n",
       "           ...,\n",
       "           [3.7884e-03, 3.8704e-03, 7.3256e-03,  ..., 1.7521e-02,\n",
       "            4.3561e-02, 8.4971e-01],\n",
       "           [1.4283e-02, 1.6060e-02, 1.4940e-02,  ..., 1.2658e-02,\n",
       "            7.1701e-02, 8.2053e-01],\n",
       "           [1.5421e-03, 4.2338e-03, 6.9933e-03,  ..., 4.7760e-03,\n",
       "            1.3307e-02, 9.5099e-01]],\n",
       " \n",
       "          [[6.2762e-03, 2.4231e-02, 2.0769e-02,  ..., 5.0046e-03,\n",
       "            3.3937e-03, 8.5598e-01],\n",
       "           [4.8519e-03, 1.7213e-02, 1.9537e-02,  ..., 4.2345e-03,\n",
       "            3.9107e-03, 9.3603e-01],\n",
       "           [7.9262e-03, 3.0831e-03, 2.2143e-03,  ..., 1.2309e-03,\n",
       "            2.2883e-03, 3.1294e-01],\n",
       "           ...,\n",
       "           [1.1145e-02, 2.5230e-03, 4.5552e-03,  ..., 8.9406e-02,\n",
       "            9.4577e-03, 5.6675e-01],\n",
       "           [3.2833e-03, 4.2312e-03, 1.7278e-02,  ..., 4.7217e-03,\n",
       "            2.0595e-02, 9.2974e-01],\n",
       "           [8.4674e-04, 4.3606e-03, 3.6536e-03,  ..., 1.1753e-03,\n",
       "            7.8321e-04, 9.8329e-01]]]]),\n",
       " tensor([[[[5.0320e-02, 9.4943e-03, 9.1387e-04,  ..., 2.7289e-04,\n",
       "            1.4855e-02, 9.1896e-01],\n",
       "           [1.1291e-01, 1.4631e-03, 2.0393e-03,  ..., 3.1542e-04,\n",
       "            5.3483e-03, 8.7305e-01],\n",
       "           [2.8479e-02, 3.7234e-03, 5.2061e-03,  ..., 6.9579e-04,\n",
       "            3.5885e-03, 9.4897e-01],\n",
       "           ...,\n",
       "           [2.9352e-02, 1.0761e-03, 7.8383e-04,  ..., 2.5258e-02,\n",
       "            6.3862e-03, 8.1772e-01],\n",
       "           [3.3512e-01, 6.6918e-04, 1.2598e-04,  ..., 1.2832e-03,\n",
       "            6.0960e-03, 6.5212e-01],\n",
       "           [2.4904e-03, 1.2068e-03, 1.4565e-04,  ..., 5.7565e-04,\n",
       "            1.3829e-03, 9.9250e-01]],\n",
       " \n",
       "          [[5.4234e-03, 5.5694e-02, 2.3030e-02,  ..., 7.4196e-02,\n",
       "            1.6568e-01, 2.3887e-01],\n",
       "           [6.0617e-02, 1.0246e-02, 1.7868e-03,  ..., 1.2925e-03,\n",
       "            1.5639e-01, 7.6415e-01],\n",
       "           [4.4270e-03, 1.7629e-01, 1.0378e-02,  ..., 9.7744e-04,\n",
       "            7.3720e-03, 7.9681e-01],\n",
       "           ...,\n",
       "           [4.8070e-03, 1.4374e-03, 2.2686e-03,  ..., 1.8194e-02,\n",
       "            1.5452e-02, 4.5828e-01],\n",
       "           [1.3265e-02, 2.4676e-03, 3.3897e-03,  ..., 3.1692e-02,\n",
       "            2.4063e-02, 8.5348e-01],\n",
       "           [5.8328e-03, 1.5899e-02, 6.6403e-03,  ..., 8.5126e-03,\n",
       "            1.1079e-02, 9.2553e-01]],\n",
       " \n",
       "          [[1.5453e-02, 4.3342e-03, 3.2693e-03,  ..., 3.0188e-03,\n",
       "            1.1150e-02, 9.4415e-01],\n",
       "           [2.2474e-02, 1.5575e-02, 4.7361e-03,  ..., 3.0462e-03,\n",
       "            3.9273e-02, 9.0406e-01],\n",
       "           [1.7872e-01, 5.9256e-02, 5.9134e-02,  ..., 3.8198e-03,\n",
       "            8.8122e-02, 5.8655e-01],\n",
       "           ...,\n",
       "           [3.4712e-02, 6.5357e-02, 2.1837e-01,  ..., 2.4032e-02,\n",
       "            3.3428e-02, 8.9796e-02],\n",
       "           [4.3921e-02, 1.7756e-02, 5.7200e-03,  ..., 9.6111e-03,\n",
       "            3.7854e-02, 8.4813e-01],\n",
       "           [4.5206e-03, 2.6636e-03, 5.9377e-04,  ..., 1.5097e-03,\n",
       "            4.2878e-03, 9.7732e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[5.6972e-03, 1.3642e-01, 5.4884e-02,  ..., 2.6501e-02,\n",
       "            2.3799e-01, 4.4883e-01],\n",
       "           [1.2438e-02, 7.1089e-02, 3.8657e-03,  ..., 3.4240e-03,\n",
       "            5.0834e-02, 8.4418e-01],\n",
       "           [1.5003e-02, 5.2429e-02, 2.1628e-02,  ..., 4.4265e-03,\n",
       "            2.4341e-02, 8.5614e-01],\n",
       "           ...,\n",
       "           [9.9044e-03, 1.8793e-02, 1.6042e-02,  ..., 1.3229e-02,\n",
       "            2.0716e-02, 7.9657e-01],\n",
       "           [9.4505e-03, 1.6554e-01, 8.0532e-02,  ..., 1.7850e-02,\n",
       "            3.9209e-02, 5.4366e-01],\n",
       "           [1.6091e-02, 6.3012e-03, 4.9166e-03,  ..., 2.0140e-03,\n",
       "            9.9249e-03, 9.5316e-01]],\n",
       " \n",
       "          [[8.2966e-03, 2.8534e-03, 1.9769e-03,  ..., 3.5600e-03,\n",
       "            1.0647e-02, 9.6327e-01],\n",
       "           [1.1188e-02, 1.5565e-03, 1.0440e-03,  ..., 1.0858e-03,\n",
       "            3.5228e-03, 9.7696e-01],\n",
       "           [7.2644e-03, 1.7408e-03, 6.4272e-03,  ..., 1.5418e-04,\n",
       "            3.5540e-03, 9.6585e-01],\n",
       "           ...,\n",
       "           [5.2133e-03, 2.5680e-04, 6.4373e-04,  ..., 9.2145e-03,\n",
       "            2.4967e-03, 9.7429e-01],\n",
       "           [7.0730e-03, 1.1928e-03, 7.6780e-04,  ..., 1.2768e-03,\n",
       "            6.1328e-03, 9.7804e-01],\n",
       "           [1.3067e-03, 1.7640e-03, 1.2307e-03,  ..., 2.3548e-03,\n",
       "            1.5736e-03, 9.8301e-01]],\n",
       " \n",
       "          [[3.1686e-01, 1.7083e-01, 7.0012e-02,  ..., 1.0282e-02,\n",
       "            6.6717e-02, 2.4197e-01],\n",
       "           [2.1584e-01, 5.6116e-02, 9.0695e-02,  ..., 2.9384e-02,\n",
       "            8.7201e-02, 1.5115e-01],\n",
       "           [2.3247e-01, 7.3445e-03, 2.4832e-02,  ..., 6.6931e-02,\n",
       "            1.2407e-01, 2.2061e-01],\n",
       "           ...,\n",
       "           [1.0468e-01, 6.5889e-03, 6.6633e-03,  ..., 1.9310e-02,\n",
       "            4.2882e-02, 7.5837e-01],\n",
       "           [9.4016e-02, 1.2812e-01, 3.4794e-02,  ..., 1.6980e-02,\n",
       "            3.3063e-02, 6.1039e-01],\n",
       "           [1.2702e-03, 5.6504e-03, 2.0764e-03,  ..., 1.9903e-03,\n",
       "            4.2644e-03, 9.7487e-01]]]]),\n",
       " tensor([[[[8.0891e-02, 9.8344e-02, 2.0221e-01,  ..., 6.3150e-02,\n",
       "            5.6755e-02, 2.3139e-01],\n",
       "           [5.8042e-03, 5.0195e-02, 1.0004e-01,  ..., 1.8827e-01,\n",
       "            6.4534e-02, 1.2400e-01],\n",
       "           [1.0829e-02, 3.7392e-02, 8.5515e-02,  ..., 1.4787e-01,\n",
       "            2.6388e-02, 9.2557e-02],\n",
       "           ...,\n",
       "           [1.1720e-02, 7.6872e-02, 9.7870e-02,  ..., 4.5383e-02,\n",
       "            1.2008e-01, 4.2537e-01],\n",
       "           [4.6586e-03, 1.1372e-01, 1.4541e-01,  ..., 1.1151e-01,\n",
       "            5.4239e-02, 1.7555e-01],\n",
       "           [9.9267e-04, 4.6353e-03, 8.8831e-04,  ..., 3.3538e-04,\n",
       "            1.8293e-02, 9.7260e-01]],\n",
       " \n",
       "          [[2.8298e-02, 1.3961e-01, 1.8071e-01,  ..., 1.0858e-02,\n",
       "            3.1189e-01, 1.6867e-01],\n",
       "           [1.7484e-01, 1.2885e-01, 2.7231e-02,  ..., 5.0759e-03,\n",
       "            1.0283e-01, 5.1314e-01],\n",
       "           [1.0768e-01, 7.7456e-02, 1.4518e-01,  ..., 1.2312e-02,\n",
       "            1.3919e-01, 2.7619e-01],\n",
       "           ...,\n",
       "           [7.6661e-02, 5.7660e-03, 1.1335e-02,  ..., 5.5463e-02,\n",
       "            8.8215e-02, 3.9132e-01],\n",
       "           [2.2224e-01, 5.0247e-02, 4.5444e-02,  ..., 8.8494e-03,\n",
       "            1.4327e-01, 4.4506e-01],\n",
       "           [1.0035e-02, 6.9327e-03, 2.8300e-03,  ..., 2.7744e-03,\n",
       "            4.4955e-03, 9.5798e-01]],\n",
       " \n",
       "          [[4.3671e-03, 2.8914e-02, 5.6276e-02,  ..., 1.8576e-02,\n",
       "            1.3457e-02, 8.0247e-01],\n",
       "           [1.2210e-02, 1.3848e-02, 9.5015e-03,  ..., 2.9838e-03,\n",
       "            2.6865e-02, 9.2125e-01],\n",
       "           [8.9962e-03, 5.7541e-02, 1.9681e-02,  ..., 9.9724e-03,\n",
       "            2.3928e-02, 8.4287e-01],\n",
       "           ...,\n",
       "           [8.2456e-03, 4.0079e-03, 7.4323e-03,  ..., 1.8271e-02,\n",
       "            8.1866e-03, 3.4524e-01],\n",
       "           [4.7122e-03, 3.9981e-03, 1.9656e-02,  ..., 1.0418e-02,\n",
       "            1.3844e-02, 8.8762e-01],\n",
       "           [3.5310e-03, 7.4166e-03, 7.8962e-03,  ..., 6.3546e-03,\n",
       "            6.8637e-03, 9.4237e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[4.4444e-02, 2.9302e-02, 8.6906e-03,  ..., 3.7000e-03,\n",
       "            2.1705e-02, 8.5565e-01],\n",
       "           [4.9381e-03, 1.3383e-01, 5.1205e-03,  ..., 3.8942e-03,\n",
       "            6.4087e-02, 7.7766e-01],\n",
       "           [5.3475e-02, 2.9352e-01, 2.1133e-02,  ..., 2.5149e-02,\n",
       "            2.1687e-01, 2.9161e-01],\n",
       "           ...,\n",
       "           [3.1786e-02, 1.2052e-02, 1.3477e-01,  ..., 1.7289e-02,\n",
       "            5.1472e-02, 1.7594e-01],\n",
       "           [1.3288e-02, 4.2668e-02, 1.5041e-02,  ..., 4.6954e-03,\n",
       "            3.2250e-02, 8.3590e-01],\n",
       "           [4.7720e-03, 2.2380e-03, 5.6734e-03,  ..., 2.3415e-03,\n",
       "            6.0620e-03, 9.6485e-01]],\n",
       " \n",
       "          [[1.1100e-02, 1.2225e-02, 6.4244e-03,  ..., 4.5120e-03,\n",
       "            1.7583e-02, 8.8954e-01],\n",
       "           [8.3709e-03, 2.2582e-03, 2.2593e-03,  ..., 7.8577e-04,\n",
       "            1.1295e-01, 8.6850e-01],\n",
       "           [1.4994e-02, 1.5771e-02, 2.7283e-02,  ..., 5.7260e-04,\n",
       "            8.1297e-02, 8.4730e-01],\n",
       "           ...,\n",
       "           [5.6485e-03, 1.8341e-03, 6.8354e-03,  ..., 1.3202e-02,\n",
       "            2.9490e-02, 5.2728e-01],\n",
       "           [1.8520e-02, 2.0409e-03, 1.7986e-03,  ..., 4.9168e-03,\n",
       "            5.1364e-02, 9.0559e-01],\n",
       "           [5.8143e-03, 3.2505e-03, 2.6351e-03,  ..., 3.0141e-03,\n",
       "            7.6998e-03, 9.5937e-01]],\n",
       " \n",
       "          [[2.6910e-02, 2.7087e-02, 4.4313e-02,  ..., 3.7156e-03,\n",
       "            1.9160e-02, 8.4764e-01],\n",
       "           [8.6293e-03, 1.4116e-01, 9.2820e-03,  ..., 3.9441e-03,\n",
       "            9.1248e-03, 8.1756e-01],\n",
       "           [3.6091e-02, 2.6428e-02, 6.5012e-02,  ..., 3.1672e-03,\n",
       "            1.8968e-02, 8.1434e-01],\n",
       "           ...,\n",
       "           [2.1075e-02, 8.8199e-03, 3.8013e-03,  ..., 7.5672e-02,\n",
       "            1.2960e-02, 7.3546e-01],\n",
       "           [1.0053e-02, 2.5204e-02, 1.9331e-02,  ..., 6.0160e-03,\n",
       "            6.9143e-02, 8.3852e-01],\n",
       "           [4.2984e-03, 3.9234e-03, 3.4331e-03,  ..., 3.2473e-03,\n",
       "            6.4506e-03, 9.6435e-01]]]]),\n",
       " tensor([[[[7.1704e-03, 1.4187e-01, 2.8265e-01,  ..., 1.2398e-01,\n",
       "            1.8200e-01, 1.3106e-02],\n",
       "           [5.4980e-02, 1.8816e-01, 1.9058e-01,  ..., 5.6933e-02,\n",
       "            1.7972e-01, 2.0085e-01],\n",
       "           [8.6877e-02, 9.9588e-02, 1.9240e-01,  ..., 5.1645e-02,\n",
       "            2.3222e-01, 1.3983e-01],\n",
       "           ...,\n",
       "           [5.6832e-02, 1.0279e-01, 1.4048e-01,  ..., 3.8445e-02,\n",
       "            2.2835e-01, 2.1407e-01],\n",
       "           [3.4398e-02, 1.9527e-01, 1.8135e-01,  ..., 1.0526e-01,\n",
       "            2.0719e-01, 4.8578e-02],\n",
       "           [9.9939e-04, 4.4350e-04, 1.1849e-03,  ..., 8.3093e-04,\n",
       "            1.8355e-03, 9.9216e-01]],\n",
       " \n",
       "          [[1.8703e-02, 9.1603e-02, 8.0946e-02,  ..., 1.8658e-02,\n",
       "            5.2633e-02, 5.8943e-01],\n",
       "           [2.7255e-03, 1.4425e-02, 8.6347e-03,  ..., 6.2756e-03,\n",
       "            3.5811e-02, 9.0643e-01],\n",
       "           [9.9596e-03, 8.7113e-02, 5.6194e-02,  ..., 3.1499e-02,\n",
       "            2.8412e-02, 5.9077e-01],\n",
       "           ...,\n",
       "           [1.4172e-03, 2.5832e-03, 3.0174e-03,  ..., 2.3307e-02,\n",
       "            1.2468e-02, 9.0934e-01],\n",
       "           [4.8893e-03, 8.7368e-02, 6.1138e-02,  ..., 2.8834e-02,\n",
       "            8.3708e-02, 6.2948e-01],\n",
       "           [1.6124e-03, 6.1572e-04, 3.7121e-04,  ..., 2.4183e-04,\n",
       "            2.0278e-03, 9.9350e-01]],\n",
       " \n",
       "          [[1.0522e-01, 3.2309e-02, 1.0780e-01,  ..., 5.7552e-02,\n",
       "            2.1942e-02, 5.6271e-01],\n",
       "           [6.2924e-03, 2.7885e-02, 4.2779e-02,  ..., 3.9977e-03,\n",
       "            3.4121e-02, 8.6262e-01],\n",
       "           [2.4963e-02, 2.7245e-02, 1.2168e-01,  ..., 1.0273e-02,\n",
       "            6.2867e-02, 6.7652e-01],\n",
       "           ...,\n",
       "           [9.7840e-03, 4.4657e-03, 5.1254e-02,  ..., 5.7406e-02,\n",
       "            4.2952e-02, 6.4437e-01],\n",
       "           [5.1543e-03, 1.2994e-01, 8.4324e-02,  ..., 6.2665e-02,\n",
       "            3.4243e-02, 5.3248e-01],\n",
       "           [2.1152e-03, 7.3715e-04, 1.4207e-03,  ..., 2.8445e-04,\n",
       "            3.0048e-03, 9.8728e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[8.9584e-03, 1.5054e-01, 8.1370e-02,  ..., 2.3654e-02,\n",
       "            2.9861e-01, 3.1247e-01],\n",
       "           [5.6337e-03, 4.1973e-01, 4.1264e-02,  ..., 1.3078e-03,\n",
       "            2.7767e-02, 4.7609e-01],\n",
       "           [1.7557e-02, 1.1506e-01, 1.8728e-01,  ..., 3.5807e-03,\n",
       "            5.2852e-02, 4.7244e-01],\n",
       "           ...,\n",
       "           [1.5274e-02, 1.8894e-02, 1.8148e-02,  ..., 3.5113e-02,\n",
       "            4.8150e-02, 6.8908e-01],\n",
       "           [1.0393e-02, 2.3292e-01, 7.1757e-02,  ..., 5.8161e-03,\n",
       "            5.3673e-02, 5.8284e-01],\n",
       "           [1.1572e-02, 4.3859e-03, 7.9939e-03,  ..., 4.1058e-03,\n",
       "            6.4308e-03, 9.4505e-01]],\n",
       " \n",
       "          [[6.1492e-01, 5.1088e-02, 8.7484e-02,  ..., 1.7179e-03,\n",
       "            6.7924e-02, 1.4547e-01],\n",
       "           [1.9010e-02, 2.7567e-02, 9.3867e-02,  ..., 1.4176e-03,\n",
       "            2.5582e-02, 8.0467e-01],\n",
       "           [1.6812e-01, 1.3609e-01, 2.1918e-01,  ..., 7.6907e-03,\n",
       "            1.1238e-01, 2.7580e-01],\n",
       "           ...,\n",
       "           [1.7975e-03, 2.1441e-03, 5.9439e-03,  ..., 9.3751e-04,\n",
       "            2.0765e-03, 9.7730e-01],\n",
       "           [5.4028e-02, 8.3944e-02, 2.3251e-01,  ..., 2.5216e-03,\n",
       "            3.8393e-02, 5.3862e-01],\n",
       "           [2.7221e-04, 2.0562e-04, 1.7879e-04,  ..., 3.0312e-05,\n",
       "            1.7386e-04, 9.9889e-01]],\n",
       " \n",
       "          [[3.7234e-03, 4.5621e-02, 2.5164e-02,  ..., 5.4443e-03,\n",
       "            1.5877e-01, 7.1480e-01],\n",
       "           [2.4116e-02, 2.9970e-02, 2.6508e-02,  ..., 2.1799e-03,\n",
       "            6.0237e-02, 8.4211e-01],\n",
       "           [2.5971e-02, 6.5680e-02, 3.7877e-02,  ..., 4.7288e-03,\n",
       "            3.4884e-02, 8.0667e-01],\n",
       "           ...,\n",
       "           [2.5144e-03, 3.9806e-03, 9.4888e-03,  ..., 9.5708e-03,\n",
       "            5.8568e-03, 8.3187e-01],\n",
       "           [6.8483e-03, 2.0131e-02, 4.1663e-02,  ..., 8.2595e-03,\n",
       "            2.4851e-02, 8.4389e-01],\n",
       "           [1.1678e-02, 8.2286e-03, 1.6774e-02,  ..., 3.2971e-03,\n",
       "            1.0905e-02, 9.2420e-01]]]]),\n",
       " tensor([[[[1.7865e-02, 4.0543e-02, 2.8695e-02,  ..., 3.9409e-02,\n",
       "            5.2647e-02, 7.1461e-01],\n",
       "           [2.2517e-03, 2.0449e-02, 1.0526e-02,  ..., 4.2858e-03,\n",
       "            2.2498e-02, 9.2336e-01],\n",
       "           [2.2422e-03, 1.8991e-02, 3.6533e-02,  ..., 1.2845e-02,\n",
       "            1.9119e-02, 8.5942e-01],\n",
       "           ...,\n",
       "           [3.3368e-03, 1.6334e-02, 1.2769e-02,  ..., 1.2132e-01,\n",
       "            3.2757e-02, 7.1266e-01],\n",
       "           [1.4352e-03, 5.8008e-03, 3.7217e-03,  ..., 7.2566e-03,\n",
       "            1.0251e-02, 9.5606e-01],\n",
       "           [2.6183e-04, 5.4154e-04, 2.9291e-04,  ..., 3.7159e-04,\n",
       "            6.2471e-04, 9.9703e-01]],\n",
       " \n",
       "          [[2.0698e-02, 1.7569e-01, 6.4511e-02,  ..., 3.7731e-02,\n",
       "            1.1663e-01, 4.2473e-01],\n",
       "           [2.0784e-02, 1.0688e-01, 3.4979e-02,  ..., 1.2659e-02,\n",
       "            4.2568e-02, 7.0933e-01],\n",
       "           [2.6259e-02, 6.9920e-02, 3.1917e-02,  ..., 1.0201e-02,\n",
       "            5.8229e-02, 7.1738e-01],\n",
       "           ...,\n",
       "           [3.7002e-02, 8.9191e-02, 3.7588e-02,  ..., 2.7954e-02,\n",
       "            1.5553e-01, 5.0139e-01],\n",
       "           [2.5141e-02, 1.1034e-01, 3.1284e-02,  ..., 1.2572e-02,\n",
       "            9.9700e-02, 6.1315e-01],\n",
       "           [8.6147e-03, 7.6629e-03, 5.7514e-03,  ..., 2.5093e-03,\n",
       "            1.5948e-02, 9.4299e-01]],\n",
       " \n",
       "          [[7.9928e-03, 1.5337e-02, 2.8132e-02,  ..., 7.4965e-03,\n",
       "            3.5509e-02, 8.2524e-01],\n",
       "           [1.6000e-02, 4.8264e-02, 8.3151e-03,  ..., 1.0717e-03,\n",
       "            2.1381e-02, 8.9164e-01],\n",
       "           [1.8409e-02, 2.5488e-02, 4.3216e-02,  ..., 2.9812e-03,\n",
       "            2.8199e-02, 8.4012e-01],\n",
       "           ...,\n",
       "           [1.9812e-02, 1.0246e-02, 9.8670e-03,  ..., 1.2062e-01,\n",
       "            3.5006e-02, 7.5987e-01],\n",
       "           [1.4768e-03, 4.4438e-03, 1.0921e-03,  ..., 1.5361e-03,\n",
       "            1.8686e-02, 9.6530e-01],\n",
       "           [2.8008e-03, 2.3177e-03, 1.6243e-03,  ..., 7.3322e-04,\n",
       "            4.2062e-03, 9.8542e-01]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[1.6945e-02, 1.6171e-02, 1.5138e-02,  ..., 2.9177e-02,\n",
       "            1.2847e-02, 7.8223e-01],\n",
       "           [2.0068e-03, 5.1651e-03, 6.1099e-03,  ..., 4.4321e-02,\n",
       "            7.5515e-03, 8.5270e-01],\n",
       "           [3.0060e-03, 4.2573e-02, 8.4366e-03,  ..., 3.7421e-02,\n",
       "            1.9860e-02, 7.4467e-01],\n",
       "           ...,\n",
       "           [7.4081e-03, 3.8061e-02, 4.3465e-03,  ..., 4.5500e-02,\n",
       "            2.6539e-02, 7.9176e-01],\n",
       "           [2.8827e-03, 3.3098e-02, 6.5061e-03,  ..., 2.9404e-02,\n",
       "            2.3000e-02, 8.2256e-01],\n",
       "           [2.5901e-03, 9.6380e-04, 1.0592e-03,  ..., 7.5770e-04,\n",
       "            1.7048e-03, 9.8991e-01]],\n",
       " \n",
       "          [[1.0844e-01, 1.2932e-01, 8.7597e-02,  ..., 4.7245e-02,\n",
       "            2.9206e-01, 1.5949e-01],\n",
       "           [5.6723e-03, 5.2409e-03, 1.2174e-02,  ..., 2.0114e-03,\n",
       "            4.4239e-03, 9.5559e-01],\n",
       "           [1.0296e-02, 1.0471e-02, 2.1517e-02,  ..., 3.5754e-03,\n",
       "            1.5889e-02, 9.1125e-01],\n",
       "           ...,\n",
       "           [1.8233e-02, 1.1293e-02, 1.9193e-02,  ..., 1.4840e-02,\n",
       "            1.4293e-02, 8.2394e-01],\n",
       "           [1.0110e-02, 1.0396e-02, 2.6000e-02,  ..., 8.7879e-03,\n",
       "            1.2644e-02, 8.8868e-01],\n",
       "           [2.0542e-03, 5.2223e-04, 1.5181e-03,  ..., 7.1042e-04,\n",
       "            1.3232e-03, 9.8937e-01]],\n",
       " \n",
       "          [[2.5067e-02, 8.1544e-02, 2.2890e-01,  ..., 7.3256e-02,\n",
       "            2.3472e-01, 6.9389e-03],\n",
       "           [5.6886e-02, 7.9059e-02, 1.8312e-01,  ..., 3.3904e-02,\n",
       "            1.6572e-01, 2.8160e-01],\n",
       "           [1.7782e-02, 2.3093e-02, 4.0276e-02,  ..., 2.7514e-02,\n",
       "            7.5532e-02, 7.0256e-01],\n",
       "           ...,\n",
       "           [3.0133e-02, 2.4860e-02, 8.2874e-02,  ..., 2.7658e-02,\n",
       "            1.3854e-01, 1.9174e-01],\n",
       "           [2.7615e-02, 7.6856e-02, 2.0417e-01,  ..., 2.6630e-02,\n",
       "            7.9648e-02, 3.0191e-01],\n",
       "           [9.3749e-03, 7.5064e-03, 3.1863e-03,  ..., 7.0246e-03,\n",
       "            9.4097e-03, 9.4605e-01]]]]),\n",
       " tensor([[[[0.0114, 0.0073, 0.0065,  ..., 0.0482, 0.0255, 0.8243],\n",
       "           [0.0133, 0.0145, 0.0039,  ..., 0.0056, 0.0182, 0.9281],\n",
       "           [0.0129, 0.0064, 0.0030,  ..., 0.0036, 0.0170, 0.9440],\n",
       "           ...,\n",
       "           [0.0102, 0.0030, 0.0015,  ..., 0.0017, 0.0109, 0.9662],\n",
       "           [0.0142, 0.0089, 0.0029,  ..., 0.0139, 0.0411, 0.9010],\n",
       "           [0.0844, 0.1376, 0.0579,  ..., 0.1114, 0.0734, 0.1720]],\n",
       " \n",
       "          [[0.0175, 0.0011, 0.0013,  ..., 0.0058, 0.0124, 0.9536],\n",
       "           [0.0024, 0.0976, 0.0043,  ..., 0.0045, 0.0353, 0.8445],\n",
       "           [0.0181, 0.0274, 0.3698,  ..., 0.0178, 0.0669, 0.3061],\n",
       "           ...,\n",
       "           [0.0055, 0.0034, 0.0245,  ..., 0.7105, 0.0232, 0.1225],\n",
       "           [0.0121, 0.0069, 0.0139,  ..., 0.0150, 0.1814, 0.7310],\n",
       "           [0.0131, 0.0666, 0.0196,  ..., 0.0671, 0.1266, 0.5002]],\n",
       " \n",
       "          [[0.0163, 0.1640, 0.1391,  ..., 0.0478, 0.0891, 0.3114],\n",
       "           [0.0074, 0.0024, 0.0237,  ..., 0.0222, 0.0111, 0.8909],\n",
       "           [0.0124, 0.0057, 0.0213,  ..., 0.0471, 0.0269, 0.8049],\n",
       "           ...,\n",
       "           [0.0077, 0.0243, 0.0211,  ..., 0.0376, 0.0435, 0.7788],\n",
       "           [0.0131, 0.0134, 0.0419,  ..., 0.0230, 0.0446, 0.8039],\n",
       "           [0.0644, 0.1379, 0.1205,  ..., 0.0617, 0.0979, 0.0967]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[0.0472, 0.0724, 0.0539,  ..., 0.0252, 0.0808, 0.6210],\n",
       "           [0.0049, 0.1337, 0.0172,  ..., 0.0083, 0.0220, 0.7852],\n",
       "           [0.0066, 0.0268, 0.0276,  ..., 0.0158, 0.0187, 0.8719],\n",
       "           ...,\n",
       "           [0.0064, 0.0173, 0.0075,  ..., 0.0377, 0.0105, 0.8987],\n",
       "           [0.0086, 0.0244, 0.0137,  ..., 0.0141, 0.0216, 0.8809],\n",
       "           [0.1068, 0.0939, 0.0976,  ..., 0.0670, 0.1079, 0.0660]],\n",
       " \n",
       "          [[0.0679, 0.0377, 0.1059,  ..., 0.1161, 0.1198, 0.2137],\n",
       "           [0.0076, 0.0650, 0.0357,  ..., 0.0098, 0.0187, 0.7628],\n",
       "           [0.0144, 0.0063, 0.0486,  ..., 0.0076, 0.0203, 0.8653],\n",
       "           ...,\n",
       "           [0.0043, 0.0031, 0.0065,  ..., 0.0120, 0.0134, 0.9429],\n",
       "           [0.0159, 0.0050, 0.0149,  ..., 0.0163, 0.0253, 0.8793],\n",
       "           [0.0332, 0.0898, 0.0739,  ..., 0.1105, 0.0763, 0.1138]],\n",
       " \n",
       "          [[0.0206, 0.0895, 0.2952,  ..., 0.0225, 0.2748, 0.0662],\n",
       "           [0.0016, 0.4197, 0.1364,  ..., 0.0179, 0.1161, 0.1685],\n",
       "           [0.0050, 0.0201, 0.4415,  ..., 0.0072, 0.0215, 0.3013],\n",
       "           ...,\n",
       "           [0.0114, 0.0148, 0.0491,  ..., 0.1933, 0.0473, 0.4999],\n",
       "           [0.0138, 0.0550, 0.0716,  ..., 0.0198, 0.3501, 0.3394],\n",
       "           [0.0039, 0.2938, 0.0944,  ..., 0.0586, 0.1020, 0.1736]]]]))"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(tokens_tensor,token_type_ids = sagment_tensors)\n",
    "    encoded_hidden = output\n",
    "encoded_hidden[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at C:\\Users\\cccql\\.cache\\huggingface\\hub\\models--bert-base-chinese\\snapshots\\38fda776740d17609554e879e3ac7b9837bdb5ee were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ -7.9952,  -7.9039,  -7.9825,  ...,  -6.9982,  -7.0039,  -7.0533],\n",
      "         [ -7.3028,  -7.6208,  -7.4104,  ...,  -5.9638,  -6.7491,  -3.6037],\n",
      "         [-18.8863, -18.8394, -18.4806,  ..., -14.1091,  -9.2716, -10.0511],\n",
      "         ...,\n",
      "         [-15.1031, -15.8225, -14.4563,  ..., -10.7002, -10.1100,  -6.4397],\n",
      "         [-11.3589, -11.2920, -10.8067,  ...,  -8.5306,  -5.9084,  -5.8770],\n",
      "         [ -9.2334,  -9.1561,  -9.3433,  ...,  -6.9585,  -6.7155,  -6.3854]]],\n",
      "       grad_fn=<ViewBackward0>)\n",
      "中\n"
     ]
    }
   ],
   "source": [
    "# 1.遮蔽语言模型\n",
    "\n",
    "# 任务一：遮蔽语言模型\n",
    "# BERT 在预训练中引入[CLS]和[SEP]标记句子和结尾\n",
    "samples = ['[CLS]中国的首都是哪里？[SEP]北京是[MASK]国的首都。[SEP]']  # 准备输入模型的语句\n",
    "\n",
    "# tokenized_text = [tokenizer.tokenize(i) for i in samples]\n",
    "# input_text = torch.LongTensor(tokenized_text)\n",
    "\n",
    "\n",
    "tokenized_text = [tokenizer.tokenize(i) for i in samples]                 #将句子分割成一个个token，即一个个汉字和分隔符\n",
    "input_ids = [tokenizer.convert_tokens_to_ids(i) for i in tokenized_text]  #把每个token转换成对应的索引\n",
    "input_ids = torch.LongTensor(input_ids)\n",
    "\n",
    "model = BertForMaskedLM.from_pretrained(MODEL_PATH)\n",
    "model.eval()\n",
    "outputs = model(input_ids)\n",
    "print(outputs[0])\n",
    "\n",
    "pre_score = outputs[0]\n",
    "sample = pre_score[0].detach().numpy()\n",
    "pred = np.argmax(sample,axis=1)\n",
    "print(tokenizer.convert_ids_to_tokens(pred)[14])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at C:\\Users\\cccql\\.cache\\huggingface\\hub\\models--bert-base-chinese\\snapshots\\38fda776740d17609554e879e3ac7b9837bdb5ee were not used when initializing BertForNextSentencePrediction: ['cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.decoder.weight', 'cls.predictions.transform.LayerNorm.weight']\n",
      "- This IS expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForNextSentencePrediction from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.9951, 1.2042],\n",
      "        [3.1683, 0.8106]], grad_fn=<AddmmBackward0>)\n",
      "[0 0]\n"
     ]
    }
   ],
   "source": [
    "# 2.句子预测任务\n",
    "\n",
    "sen_code1 = tokenizer.encode_plus('天气怎么样','今天的天气很好啊')\n",
    "sen_code2 = tokenizer.encode_plus('飞机在天上','我在吃披萨和牛排')\n",
    "\n",
    "tokens_tensor = torch.tensor([sen_code1['input_ids'],sen_code2['input_ids']])\n",
    "model = BertForNextSentencePrediction.from_pretrained(MODEL_PATH)   \n",
    "model.eval()\n",
    "outputs = model(tokens_tensor)\n",
    "seq_relationship_scores = outputs[0]\n",
    "print(seq_relationship_scores)\n",
    "sample = seq_relationship_scores.detach().numpy()\n",
    "pred = np.argmax(sample,axis = 1)\n",
    "print(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 前面三行代码等价于：\n",
    "samples = [\"[CLS]今天天气怎么样[SEP]今天天气很好[SEP]\", \"[CLS]小明今年几岁了[SEP]我不喜欢学习[SEP]\"]\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "tokenized_text = [tokenizer.tokenize(i) for i in samples]                  \n",
    "input_ids = [tokenizer.convert_tokens_to_ids(i) for i in tokenized_text]   \n",
    "\n",
    "tokens_tensor = torch.LongTensor(input_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['[CLS]', '里', '昂', '是', '谁', '[SEP]', '里', '昂', '是', '一', '个', '杀', '手', '[SEP]']\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "argmax(): argument 'input' (position 1) must be Tensor, not str",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_17568\\310363024.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m  \u001b[1;31m# 对输出的答案进行解码的过程\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 28\u001b[1;33m \u001b[0manswer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m' '\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_tokens\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_pos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_pos\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     29\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;31m# 每次执行的结果不一致，这里因为没有经过微调，所以效果不是很好，输出结果不佳，下面的输出是其中的一种。\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: argmax(): argument 'input' (position 1) must be Tensor, not str"
     ]
    }
   ],
   "source": [
    "from transformers import BertForQuestionAnswering\n",
    "model_name = 'bert-base-chinese'\n",
    "\n",
    " # 通过词典导入分词器\n",
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    " # 导入配置文件\n",
    "model_config = BertConfig.from_pretrained(model_name)\n",
    "  # 最终有两个输出，初始位置和结束位置\n",
    "model_config.num_labels = 2\n",
    " \n",
    "# 根据bert的model_config新建BertForQuestionAnswering\n",
    "model = BertForQuestionAnswering(model_config)\n",
    "model.eval()\n",
    "\n",
    "question, text = \"里昂是谁\", \"里昂是一个杀手\"\n",
    " \n",
    "sen_code = tokenizer.encode_plus(question,text)\n",
    "\n",
    "tokens_tensor = torch.tensor([sen_code['input_ids']])\n",
    "segments_tensor = torch.tensor([sen_code['token_type_ids']])\n",
    "\n",
    "start_pos, end_pos = model(tokens_tensor, segments_tensor)\n",
    " # 进行逆编码，得到原始的token\n",
    "all_tokens = tokenizer.convert_ids_to_tokens(sen_code['input_ids'])\n",
    "print(all_tokens)               #['[CLS]', '里', '昂', '是', '谁', '[SEP]', '里', '昂', '是', '一', '个', '杀', '手', '[SEP]']\n",
    "\n",
    " # 对输出的答案进行解码的过程\n",
    "answer = ' '.join(all_tokens[torch.argmax(start_pos,axis = 1) : torch.argmax(end_pos,axis = 1)+1])\n",
    "\n",
    "# 每次执行的结果不一致，这里因为没有经过微调，所以效果不是很好，输出结果不佳，下面的输出是其中的一种。\n",
    "print(answer)                    #一 个 杀 手 [SEP]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('pytorch113')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "8890138424c629f4319e8e5bf998ba330dece0d7c30b28e728ca81bd99325941"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
